{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapy 1.6.0 - project: autocrawler\n",
      "\n",
      "Usage:\n",
      "  scrapy <command> [options] [args]\n",
      "\n",
      "Available commands:\n",
      "  bench         Run quick benchmark test\n",
      "  check         Check spider contracts\n",
      "  crawl         Run a spider\n",
      "  edit          Edit spider\n",
      "  fetch         Fetch a URL using the Scrapy downloader\n",
      "  genspider     Generate new spider using pre-defined templates\n",
      "  list          List available spiders\n",
      "  parse         Parse URL (using its spider) and print the results\n",
      "  runspider     Run a self-contained spider (without creating a project)\n",
      "  settings      Get settings values\n",
      "  shell         Interactive scraping console\n",
      "  startproject  Create new project\n",
      "  version       Print Scrapy version\n",
      "  view          Open URL in browser, as seen by Scrapy\n",
      "\n",
      "Use \"scrapy <command> -h\" to see more info about a command\n"
     ]
    }
   ],
   "source": [
    "!activate ScrapyEnvironment\n",
    "! scrapy -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ada6385eab15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# import items from items.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutocrawlerItem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mScoutAutoCrawler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscrapy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpider\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "# Importing scrapy\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "# Defining the spider class\n",
    "# MMWD: Multiple Models With Details\n",
    "\n",
    "# import items from items.py\n",
    "\n",
    "from ..items import AutocrawlerItem\n",
    "\n",
    "class ScoutAutoCrawler(scrapy.Spider):\n",
    "    \n",
    "    name = \"scout_mmwd\"\n",
    "    \n",
    "    allowed_domains = [\"autoscout24.com\"]\n",
    "    \n",
    "    def start_requests( self ):         \n",
    "        page_number = 1\n",
    "        base_url = \"https://www.autoscout24.com/\"\n",
    "        makes = ['cupra', 'other',]\n",
    "        #models = {\"audi\" : ['a4', 'a6', 'a5'],\n",
    "        #          \"opel\" : ['corsa', 'adam', 'meriva'],\n",
    "        #          \"renault\" : ['clio', 'duster', 'scenic']\n",
    "        #          }\n",
    "        #years = [\"2014\", \"2015\"]\n",
    "        #desc = [\"0\", \"1\"]\n",
    "        #gear = [\"A\", \"M\", \"S\"]\n",
    "        \n",
    "        \n",
    "        #for i in range(3):\n",
    "        #    l = len(models[makes[i]])\n",
    "        #    for x in range(l):\n",
    "        #        for y in range(2):\n",
    "        #            for a in range(2):\n",
    "        #                for g in range(3):\n",
    "        #                    for page_number in range(1,21):\n",
    "        #                \n",
    "        #                        url = base_url+\"lst/\"+makes[i]+\"/\"+models[makes[i]][x]+\"?sort=price&\\\n",
    "        #                        desc=\"+desc[a]+\"&gear=\"+gear[g]+\"&ustate=N%2CU&size=20&page=\"+str(page_number)+\"&\\\n",
    "        #                        fregto=\"+years[y]+\"&fregfrom=\"+years[y]+\"&atype=C&\"\n",
    "        \n",
    "        for page_number in range(1,21):\n",
    "            url = base_url + \"lst/cupra/\" + makes[i] + \"?sort=price&desc=0&ustate=N%2CU&size=20\\\n",
    "            &page=\" + str(page_number) + \"1&atype=C&\"\n",
    "        \n",
    "            yield scrapy.Request( url = url, dont_filter = False, callback = self.parse) \n",
    "    \n",
    "\n",
    "    def parse(self, response):\n",
    "        \n",
    "        base_url = \"https://www.autoscout24.com/\"\n",
    "        all_auto_divs = response.css(\".cldt-summary-full-item-main\")\n",
    "        \n",
    "        for auto_divs in all_auto_divs:\n",
    "            \n",
    "            #advertisement details link finder\n",
    "            detail_page = auto_divs.css(\".cldt-summary-titles\")\n",
    "            link = detail_page.css('a::attr(href)').extract_first()          \n",
    "        \n",
    "            yield scrapy.Request( url = base_url+link, callback = self.parse_details)\n",
    "        \n",
    "    \n",
    "    def parse_details(self, response):\n",
    "        \n",
    "        items = AutocrawlerItem()\n",
    "        \n",
    "        headline = response.css(\".cldt-headline\")\n",
    "        make_model = headline.css(\"h1.cldt-detail-title > span:nth-child(1) ::text\").extract_first()\n",
    "        short_description = headline.css(\"h1.cldt-detail-title > span:nth-child(2) ::text\").extract_first()\n",
    "        body_type = headline.css(\"h4.cldt-detail-subheadline ::text\").extract_first()\n",
    "        \n",
    "        stage = response.css(\".cldt-stage-data\")\n",
    "        price = stage.css(\"div.cldt-price > h2 ::text\").extract_first()\n",
    "        vat = stage.css(\"div.cldt-stage-headline > div:nth-child(2) > p > span ::text\").extract()\n",
    "        km = stage.css(\"div.cldt-stage-basic-data > div:nth-child(1) > span ::text\").extract()\n",
    "        registration = stage.css(\"div.cldt-stage-basic-data > div:nth-child(2) > span ::text\").extract()\n",
    "        kW = stage.css(\"div.cldt-stage-basic-data > div:nth-child(3) > span:nth-child(1) ::text\").extract()\n",
    "        hp = stage.css(\"div.cldt-stage-basic-data > div:nth-child(3) > span:nth-child(2) ::text\").extract()\n",
    "        \n",
    "        items[\"url\"] = response.url\n",
    "        \n",
    "        Details = response.css(\"div.cldt-item[data-item-name='car-details']\")\n",
    "        details = Details.css(\"div.sc-grid-row > div:nth-child(1)\")\n",
    "        #details\n",
    "        state_1 = details.css(\"div:nth-child(1) > dl > dt:nth-child(1) ::text\").extract_first()\n",
    "        state_2 = details.css(\"div:nth-child(1) > dl > dd:nth-child(2) ::text\").extract()\n",
    "        \n",
    "        state_3 = details.css(\"div:nth-child(1) > dl > dt:nth-child(3) ::text\").extract_first()\n",
    "        state_4 = details.css(\"div:nth-child(1) > dl > dd:nth-child(4) ::text\").extract()\n",
    "        \n",
    "        state_5 = details.css(\"div:nth-child(1) > dl > dt:nth-child(5) ::text\").extract_first()\n",
    "        state_6 = details.css(\"div:nth-child(1) > dl > dd:nth-child(6) ::text\").extract()\n",
    "        \n",
    "        state_7 = details.css(\"div:nth-child(1) > dl > dt:nth-child(7) ::text\").extract_first()\n",
    "        state_8 = details.css(\"div:nth-child(1) > dl > dd:nth-child(8) ::text\").extract()\n",
    "        \n",
    "        state_9 = details.css(\"div:nth-child(1) > dl > dt:nth-child(9) ::text\").extract_first()\n",
    "        state_10 = details.css(\"div:nth-child(1) > dl > dd:nth-child(10) ::text\").extract()\n",
    "        \n",
    "        state_11 = details.css(\"div:nth-child(1) > dl > dt:nth-child(11) ::text\").extract_first()\n",
    "        state_12 = details.css(\"div:nth-child(1) > dl > dd:nth-child(12) ::text\").extract()\n",
    "        \n",
    "        state_13 = details.css(\"div:nth-child(1) > dl > dt:nth-child(13) ::text\").extract_first()\n",
    "        state_14 = details.css(\"div:nth-child(1) > dl > dd:nth-child(14) ::text\").extract()\n",
    "        \n",
    "        state_15 = details.css(\"div:nth-child(1) > dl > dt:nth-child(15) ::text\").extract_first()\n",
    "        state_16 = details.css(\"div:nth-child(1) > dl > dd:nth-child(16) ::text\").extract()\n",
    "        \n",
    "        state_17 = details.css(\"div:nth-child(1) > dl > dt:nth-child(17) ::text\").extract_first()\n",
    "        state_18 = details.css(\"div:nth-child(1) > dl > dd:nth-child(18) ::text\").extract()\n",
    "        \n",
    "        state_19 = details.css(\"div:nth-child(1) > dl > dt:nth-child(19) ::text\").extract_first()\n",
    "        state_20 = details.css(\"div:nth-child(1) > dl > dd:nth-child(20) ::text\").extract()\n",
    "        \n",
    "        #properties\n",
    "        properties_1 = details.css(\"div:nth-child(2) > dl > dt:nth-child(1) ::text\").extract_first()\n",
    "        properties_2 = details.css(\"div:nth-child(2) > dl > dd:nth-child(2) ::text\").extract()\n",
    "        \n",
    "        properties_3 = details.css(\"div:nth-child(2) > dl > dt:nth-child(3) ::text\").extract_first()        \n",
    "        properties_4 = details.css(\"div:nth-child(2) > dl > dd:nth-child(4) ::text\").extract()\n",
    "\n",
    "        properties_5 = details.css(\"div:nth-child(2) > dl > dt:nth-child(5) ::text\").extract_first()        \n",
    "        properties_6 = details.css(\"div:nth-child(2) > dl > dd:nth-child(6) ::text\").extract()\n",
    "\n",
    "        properties_7 = details.css(\"div:nth-child(2) > dl > dt:nth-child(7) ::text\").extract_first()        \n",
    "        properties_8 = details.css(\"div:nth-child(2) > dl > dd:nth-child(8) ::text\").extract()\n",
    "\n",
    "        properties_9 = details.css(\"div:nth-child(2) > dl > dt:nth-child(9) ::text\").extract_first()        \n",
    "        properties_10 = details.css(\"div:nth-child(2) > dl > dd:nth-child(10) ::text\").extract()\n",
    "\n",
    "        properties_11 = details.css(\"div:nth-child(2) > dl > dt:nth-child(11) ::text\").extract_first()\n",
    "        properties_12 = details.css(\"div:nth-child(2) > dl > dd:nth-child(12) ::text\").extract()\n",
    "        \n",
    "        properties_13 = details.css(\"div:nth-child(2) > dl > dt:nth-child(13) ::text\").extract_first()        \n",
    "        properties_14 = details.css(\"div:nth-child(2) > dl > dd:nth-child(14) ::text\").extract()\n",
    "\n",
    "        properties_15 = details.css(\"div:nth-child(2) > dl > dt:nth-child(15) ::text\").extract_first()        \n",
    "        properties_16 = details.css(\"div:nth-child(2) > dl > dd:nth-child(16) ::text\").extract()\n",
    "\n",
    "        properties_17 = details.css(\"div:nth-child(2) > dl > dt:nth-child(17) ::text\").extract_first()        \n",
    "        properties_18 = details.css(\"div:nth-child(2) > dl > dd:nth-child(18) ::text\").extract()\n",
    "\n",
    "        properties_19 = details.css(\"div:nth-child(2) > dl > dt:nth-child(19) ::text\").extract_first()        \n",
    "        properties_20 = details.css(\"div:nth-child(2) > dl > dd:nth-child(20) ::text\").extract()\n",
    "\n",
    "        properties_21 = details.css(\"div:nth-child(2) > dl > dt:nth-child(21) ::text\").extract_first()\n",
    "        properties_22 = details.css(\"div:nth-child(2) > dl > dd:nth-child(22) ::text\").extract()\n",
    "        \n",
    "        properties_23 = details.css(\"div:nth-child(2) > dl > dt:nth-child(23) ::text\").extract_first()        \n",
    "        properties_24 = details.css(\"div:nth-child(2) > dl > dd:nth-child(24) ::text\").extract()\n",
    "\n",
    "        properties_25 = details.css(\"div:nth-child(2) > dl > dt:nth-child(25) ::text\").extract_first()        \n",
    "        properties_26 = details.css(\"div:nth-child(2) > dl > dd:nth-child(26) ::text\").extract()\n",
    "\n",
    "        properties_27 = details.css(\"div:nth-child(2) > dl > dt:nth-child(27) ::text\").extract_first()        \n",
    "        properties_28 = details.css(\"div:nth-child(2) > dl > dd:nth-child(28) ::text\").extract()\n",
    "\n",
    "        properties_29 = details.css(\"div:nth-child(2) > dl > dt:nth-child(29) ::text\").extract_first()        \n",
    "        properties_30 = details.css(\"div:nth-child(2) > dl > dd:nth-child(30) ::text\").extract()\n",
    "\n",
    "        #drive\n",
    "        drive_1 = details.css(\"div:nth-child(3) > dl > dt:nth-child(1) ::text\").extract_first()        \n",
    "        drive_2 = details.css(\"div:nth-child(3) > dl > dd:nth-child(2) ::text\").extract()\n",
    "\n",
    "        drive_3 = details.css(\"div:nth-child(3) > dl > dt:nth-child(3) ::text\").extract_first()        \n",
    "        drive_4 = details.css(\"div:nth-child(3) > dl > dd:nth-child(4) ::text\").extract()\n",
    "\n",
    "        drive_5 = details.css(\"div:nth-child(3) > dl > dt:nth-child(5) ::text\").extract_first()        \n",
    "        drive_6 = details.css(\"div:nth-child(3) > dl > dd:nth-child(6) ::text\").extract()\n",
    "\n",
    "        drive_7 = details.css(\"div:nth-child(3) > dl > dt:nth-child(7) ::text\").extract_first()        \n",
    "        drive_8 = details.css(\"div:nth-child(3) > dl > dd:nth-child(8) ::text\").extract()\n",
    "\n",
    "        drive_9 = details.css(\"div:nth-child(3) > dl > dt:nth-child(9) ::text\").extract_first()        \n",
    "        drive_10 = details.css(\"div:nth-child(3) > dl > dd:nth-child(10) ::text\").extract()\n",
    "\n",
    "        drive_11 = details.css(\"div:nth-child(3) > dl > dt:nth-child(11) ::text\").extract_first()        \n",
    "        drive_12 = details.css(\"div:nth-child(3) > dl > dd:nth-child(12) ::text\").extract()\n",
    "\n",
    "        drive_13 = details.css(\"div:nth-child(3) > dl > dt:nth-child(13) ::text\").extract_first()        \n",
    "        drive_14 = details.css(\"div:nth-child(3) > dl > dd:nth-child(14) ::text\").extract()\n",
    "\n",
    "        drive_15 = details.css(\"div:nth-child(3) > dl > dt:nth-child(15) ::text\").extract_first()        \n",
    "        drive_16 = details.css(\"div:nth-child(3) > dl > dd:nth-child(16) ::text\").extract()\n",
    "\n",
    "        drive_17 = details.css(\"div:nth-child(3) > dl > dt:nth-child(17) ::text\").extract_first()        \n",
    "        drive_18 = details.css(\"div:nth-child(3) > dl > dd:nth-child(18) ::text\").extract()\n",
    "\n",
    "        drive_19 = details.css(\"div:nth-child(3) > dl > dt:nth-child(19) ::text\").extract_first()        \n",
    "        drive_20 = details.css(\"div:nth-child(3) > dl > dd:nth-child(20) ::text\").extract()\n",
    "\n",
    "        #environment\n",
    "        environment = Details.css(\"div.sc-grid-row > div:nth-child(2) > div > div > div\")\n",
    "        \n",
    "        environment_1 = environment.css(\"div:nth-child(1) > dl > dt:nth-child(1) ::text\").extract_first()\n",
    "        environment_2 = environment.css(\"div:nth-child(1) > dl > dd:nth-child(2) ::text\").extract()\n",
    "        \n",
    "        environment_3 = environment.css(\"div:nth-child(1) > dl > dt:nth-child(3) ::text\").extract_first()\n",
    "        environment_4a = environment.css(\"div:nth-child(1) > dl > dd:nth-child(4) > div:nth-child(1) ::text\").extract()\n",
    "        environment_4b = environment.css(\"div:nth-child(1) > dl > dd:nth-child(4) > div:nth-child(2) ::text\").extract()\n",
    "        environment_4c = environment.css(\"div:nth-child(1) > dl > dd:nth-child(4) > div:nth-child(3) ::text\").extract()\n",
    "        \n",
    "        environment_5 = environment.css(\"div:nth-child(1) > dl > dt:nth-child(5) ::text\").extract_first()\n",
    "        environment_6 = environment.css(\"div:nth-child(1) > dl > dd:nth-child(6) ::text\").extract()\n",
    "        \n",
    "        environment_7 = environment.css(\"div:nth-child(1) > dl > dt:nth-child(7) ::text\").extract_first()\n",
    "        environment_8 = environment.css(\"div:nth-child(1) > dl > dd:nth-child(8) ::text\").extract()\n",
    "        \n",
    "\n",
    "        #Equipment\n",
    "        Equipment = response.css(\"div.cldt-item[data-item-name='equipments']\")\n",
    "        equipment_1 = Equipment.css(\"div.sc-grid-row > div:nth-child(1) > h3 ::text\").extract_first()\n",
    "        equipment_2 = Equipment.css(\"div.sc-grid-row > div:nth-child(1) span::text\").extract()\n",
    "        \n",
    "        equipment_3 = Equipment.css(\"div.sc-grid-row > div:nth-child(2) > h3 ::text\").extract_first()\n",
    "        equipment_4 = Equipment.css(\"div.sc-grid-row > div:nth-child(2) span::text\").extract()        \n",
    "        \n",
    "        equipment_5 = Equipment.css(\"div.sc-grid-row > div:nth-child(3) > h3 ::text\").extract_first()\n",
    "        equipment_6 = Equipment.css(\"div.sc-grid-row > div:nth-child(3) span::text\").extract()        \n",
    "        \n",
    "        equipment_7 = Equipment.css(\"div.sc-grid-row > div:nth-child(4) > h3 ::text\").extract_first()\n",
    "        equipment_8 = Equipment.css(\"div.sc-grid-row > div:nth-child(4) span::text\").extract()        \n",
    "        \n",
    "        #Description\n",
    "        Description = response.css(\"div.cldt-item[data-item-name='description']\")\n",
    "        description = Description.css(\"div.sc-grid-row > div:nth-child(1) > div:nth-child(1) ::text\").extract()\n",
    "        \n",
    "        # saving to dictionary\n",
    "        \n",
    "        items[\"make_model\"] = make_model\n",
    "        items[\"short_description\"] = short_description\n",
    "        items[\"body_type\"] = body_type\n",
    "        items[\"price\"] = price\n",
    "        items[\"vat\"] = vat\n",
    "        items[\"km\"] = km\n",
    "        items[\"registration\"] = registration\n",
    "        items[\"kW\"] = kW\n",
    "        items[\"hp\"] = hp\n",
    "          \n",
    "        items[state_1] = state_2\n",
    "        items[state_3] = state_4\n",
    "        items[state_5] = state_6\n",
    "        items[state_7] = state_8\n",
    "        items[state_9] = state_10\n",
    "        items[state_11] = state_12\n",
    "        items[state_13] = state_14\n",
    "        items[state_15] = state_16\n",
    "        items[state_17] = state_18\n",
    "        items[state_19] = state_20\n",
    "        \n",
    "        items[properties_1] = properties_2\n",
    "        items[properties_3] = properties_4\n",
    "        items[properties_5] = properties_6\n",
    "        items[properties_7] = properties_8\n",
    "        items[properties_9] = properties_10\n",
    "        items[properties_11] = properties_12\n",
    "        items[properties_13] = properties_14\n",
    "        items[properties_15] = properties_16\n",
    "        items[properties_17] = properties_18\n",
    "        items[properties_19] = properties_20\n",
    "        items[properties_21] = properties_22\n",
    "        items[properties_23] = properties_24\n",
    "        items[properties_25] = properties_26\n",
    "        items[properties_27] = properties_28\n",
    "        items[properties_29] = properties_30\n",
    "        \n",
    "        items[drive_1] = drive_2\n",
    "        items[drive_3] = drive_4\n",
    "        items[drive_5] = drive_6\n",
    "        items[drive_7] = drive_8\n",
    "        items[drive_9] = drive_10\n",
    "        items[drive_11] = drive_12\n",
    "        items[drive_13] = drive_14\n",
    "        items[drive_15] = drive_16\n",
    "        items[drive_17] = drive_18\n",
    "        items[drive_19] = drive_20\n",
    "        \n",
    "        items[environment_1] = environment_2\n",
    "        items[environment_3] = [environment_4a, environment_4b, environment_4c]\n",
    "        items[environment_5] = environment_6\n",
    "        items[environment_7] = environment_8\n",
    "        \n",
    "        items[equipment_1] = equipment_2\n",
    "        items[equipment_3] = equipment_4\n",
    "        items[equipment_5] = equipment_6\n",
    "        items[equipment_7] = equipment_8\n",
    "        \n",
    "        items[\"description\"] = description\n",
    "        \n",
    "        yield items\n",
    "\n",
    "#! scrapy crawl scout_mmwd            \n",
    "process = CrawlerProcess({'FEED_URI': 'scout_mmwd.json',}) \n",
    " \n",
    "process.crawl(ScoutAutoCrawler) \n",
    " \n",
    "process.start() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['line 1', 'line 2', 'line 3', 'line 4']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"line 1\\nline 2\\nline 3\\nline 4\"\n",
    "text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 20:06:05 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: autocrawler)\n",
      "2019-06-20 20:06:05 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.0, Python 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Windows-10-10.0.17134-SP0\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\buono\\Anaconda3\\lib\\site-packages\\scrapy\\spiderloader.py\", line 69, in load\n",
      "    return self._spiders[spider_name]\n",
      "KeyError: 'scout_mmwd'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\buono\\Anaconda3\\Scripts\\scrapy-script.py\", line 10, in <module>\n",
      "    sys.exit(execute())\n",
      "  File \"C:\\Users\\buono\\Anaconda3\\lib\\site-packages\\scrapy\\cmdline.py\", line 150, in execute\n",
      "    _run_print_help(parser, _run_command, cmd, args, opts)\n",
      "  File \"C:\\Users\\buono\\Anaconda3\\lib\\site-packages\\scrapy\\cmdline.py\", line 90, in _run_print_help\n",
      "    func(*a, **kw)\n",
      "  File \"C:\\Users\\buono\\Anaconda3\\lib\\site-packages\\scrapy\\cmdline.py\", line 157, in _run_command\n",
      "    cmd.run(args, opts)\n",
      "  File \"C:\\Users\\buono\\Anaconda3\\lib\\site-packages\\scrapy\\commands\\crawl.py\", line 57, in run\n",
      "    self.crawler_process.crawl(spname, **opts.spargs)\n",
      "  File \"C:\\Users\\buono\\Anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 171, in crawl\n",
      "    crawler = self.create_crawler(crawler_or_spidercls)\n",
      "  File \"C:\\Users\\buono\\Anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 200, in create_crawler\n",
      "    return self._create_crawler(crawler_or_spidercls)\n",
      "  File \"C:\\Users\\buono\\Anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 204, in _create_crawler\n",
      "    spidercls = self.spider_loader.load(spidercls)\n",
      "  File \"C:\\Users\\buono\\Anaconda3\\lib\\site-packages\\scrapy\\spiderloader.py\", line 71, in load\n",
      "    raise KeyError(\"Spider not found: {}\".format(spider_name))\n",
      "KeyError: 'Spider not found: scout_mmwd'\n"
     ]
    }
   ],
   "source": [
    "! scrapy crawl scout_mmwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
